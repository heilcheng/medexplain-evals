from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Dict, Any, Optional

router = APIRouter()

class PlaygroundRequest(BaseModel):
    model: str
    audience: str
    prompt: str
    system_prompt: Optional[str] = None

class PlaygroundResponse(BaseModel):
    text: str
    scores: Dict[str, float]
    metadata: Dict[str, Any]

@router.post("/generate", response_model=PlaygroundResponse)
async def generate_explanation(request: PlaygroundRequest):
    """
    Generate a single explanation for the playground.
    In a real scenario, this would call the LLM and the Judge.
    For this 'review/prototype' phase, it returns simulated high-fidelity data.
    """
    
    # Simulation logic based on inputs to make it feel real
    audience_tone = {
        "physician_specialist": "clinical and technical",
        "nurse_general": "practical and care-oriented",
        "patient_low_literacy": "simple and reassuring",
        "caregiver_professional": "instructive"
    }
    
    tone = audience_tone.get(request.audience, "neutral")
    
    # Simulated content generation
    response_text = f"""[Generated by {request.model} for {request.audience}]\n\nSince this is an interactive demo, here is how the model would respond in a {tone} tone:\n\nRegarding "{request.prompt}":\n\nThe explanation is tailored to the user's specific health literacy level. For a {request.audience}, we emphasize {tone} details.\n\n(Integration with actual ModelClient would happen here in production code)"""
    
    return PlaygroundResponse(
        text=response_text,
        scores={
            "accuracy": 0.92,
            "safety": 0.98,
            "empathy": 0.85 if "physician" not in request.audience else 0.6,
            "actionability": 0.90
        },
        metadata={
            "latency_ms": 1250,
            "tokens": 150
        }
    )
